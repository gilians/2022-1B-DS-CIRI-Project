{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d519fd-0dfa-473a-9747-9a209ac62b0c",
   "metadata": {},
   "source": [
    "# Data Science project: CIRI\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76db8f2-e90d-4ad5-9fdc-0e850d3c8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from enum import Enum\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced99f0-ad83-4613-8880-0b2cb63bf1c9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835e204-e1a4-4738-9103-84074c7b97d3",
   "metadata": {},
   "source": [
    "## Generic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb296568-3ca8-4dfc-80bd-2f758ec71899",
   "metadata": {},
   "source": [
    "Set the device. Using CUDA on CUDA-enabled devices speeds up the use of convolutional networks significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd0421d-267f-4b2a-aebc-4fe56ac71c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_enabled = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\" if cuda_enabled else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8900377-950c-43e4-a2c4-85cec53a834c",
   "metadata": {},
   "source": [
    "We will be using a random number generator every now and then throughout this notebook. By initializing it here, we can change a single seed to obtain the same/different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3d7889-252f-409a-873f-3edd809f136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e59d07-8d93-40e6-a592-2ead337d4641",
   "metadata": {},
   "source": [
    "We create the descriptors through transfer learning. We remove the last fully-connected (classification) layers of pre-trained models and use the output of the convolutional part of the respective model as descriptors. We do this for:\n",
    "\n",
    "- VGG16\n",
    "\n",
    "These models were chosen because of ... **TODO: List reasons for choosing models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5276e7c-eac0-468c-a309-57e1a2484ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32281c8-1031-4f76-ac3b-2572ffdd320d",
   "metadata": {},
   "source": [
    "Because the images were pre-processed in another notebook, they must now be loaded into this one. To do so, we use a custom class taken from https://medium.com/codex/saving-and-loading-transformed-image-tensors-in-pytorch-f37b4daa9658."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f60049-ab3a-416c-8ea8-1af11bd6be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prepped_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, img, mask):\n",
    "        self.img = img  #img path\n",
    "        self.mask = mask  #mask path\n",
    "        self.len = len(os.listdir(self.img))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ls_img = sorted(os.listdir(self.img))\n",
    "        ls_mask = sorted(os.listdir(self.mask))\n",
    "\n",
    "        img_file_path = os.path.join(self.img, ls_img[index])\n",
    "        img_tensor = torch.load(img_file_path)\n",
    "\n",
    "        mask_file_path = os.path.join(self.mask, ls_mask[index])\n",
    "        mask_tensor = torch.load(mask_file_path)\n",
    "\n",
    "        return img_tensor, mask_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3f68a8-e5e0-4a61-8bba-c030e5cc56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = prepped_data('./content/train_loader/img', './content/train_loader/target')\n",
    "data_test = prepped_data('./content/test_loader/img', './content/test_loader/target')\n",
    "\n",
    "with open('./content/data_classes.bin', 'rb') as file:\n",
    "    data_classes = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797aa699-6e78-43eb-834b-03e92074a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataType(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Represents a dataset from which data, targets and dataloaders can be easily\n",
    "    extracted. Used mostly as a Data Transfer Object to reduce the need to pass\n",
    "    high numbers of parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, classes):\n",
    "        \"\"\"\n",
    "        Keyword arguments:\n",
    "        data   -- dictionary of dataset labels mapped to corresponding Datasets\n",
    "        classes -- a list of all classes that exist in the Datasets\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.all_classes = classes\n",
    "\n",
    "        self.targets = {}\n",
    "        for label, data in self.data.items():\n",
    "            self.targets[label] = self._get_targets(data)\n",
    "\n",
    "        self.dataloaders = {}\n",
    "        for label, data in self.data.items():\n",
    "            self.dataloaders[label] = DataLoader(\n",
    "                data,\n",
    "                batch_size=4,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "    def _get_targets(self, data):\n",
    "        return [target for (_, target) in data]\n",
    "\n",
    "\n",
    "dataset = Dataset(\n",
    "    {\n",
    "        DataType.TRAIN: data_train,\n",
    "        DataType.TEST: data_test\n",
    "    },\n",
    "    data_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283441ef-cf5f-431a-aa00-3ebb6bca34f9",
   "metadata": {},
   "source": [
    "## Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc23231-6f30-4a2e-a688-6064ef8edaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \"\"\"\n",
    "    Represents a generic convolutional model that is used for transfer\n",
    "    learning, from which descriptors can be extracted for classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, name):\n",
    "        self.model = model\n",
    "        self.name = name\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            # As the model will not be trained, gradients are not required.\n",
    "            # Disabling them speeds up performance.\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model.eval()\n",
    "        self.remove_classifier()\n",
    "\n",
    "    def remove_classifier(self):\n",
    "        \"\"\"\n",
    "        Removes the last fully connected layer (the classifier) from the\n",
    "        model, allowing the extraction of descriptors.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "    def descriptors(self, dataloader, as_numpy=True):\n",
    "        \"\"\"\n",
    "        Returns the output of the model for all items in the dataloader.\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        with torch.no_grad():\n",
    "            for data, targets in tqdm.tqdm(dataloader):\n",
    "                data = data.to(device)\n",
    "                output = self.model(data).detach()\n",
    "                outputs.extend(output)\n",
    "\n",
    "        if as_numpy:\n",
    "            outputs = np.array([output.cpu().numpy() for output in outputs])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "models = []\n",
    "if cuda_enabled:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982321e-151f-43a8-a548-5355ea705d8f",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a31661-d35c-496c-9f87-d1d64f3fc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg16Model(Model):\n",
    "    def __init__(self):\n",
    "        model = torchvision.models.vgg16(weights=\"DEFAULT\")\n",
    "        super().__init__(model, \"VGG16\")\n",
    "\n",
    "    def remove_classifier(self):\n",
    "        self.model.classifier = nn.Identity()\n",
    "\n",
    "\n",
    "vgg16 = Vgg16Model()\n",
    "vgg16.to(device)\n",
    "\n",
    "models.append(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40927677-2806-4313-a94c-8b7370da4ac4",
   "metadata": {},
   "source": [
    "### Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1beeee9-c082-4f38-999e-aff07ceeb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV3Model(Model):\n",
    "    def __init__(self):\n",
    "        model = torchvision.models.inception_v3(weights=\"DEFAULT\")\n",
    "        super().__init__(model, \"InceptionV3\")\n",
    "\n",
    "    def remove_classifier(self):\n",
    "        self.model.fc = nn.Identity()\n",
    "\n",
    "\n",
    "inception = InceptionV3Model()\n",
    "inception.to(device)\n",
    "\n",
    "models.append(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e8a9c-b5ff-47fd-8ec2-724dd95a8288",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "### Obtain image descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7ef902-5160-428d-942d-16bacadd1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptorManager:\n",
    "    \"\"\"\n",
    "    Handles the loading, saving and extraction of data descriptors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, base_path=\"./data/descriptors\"):\n",
    "        self.model = model\n",
    "        self.base_path = base_path\n",
    "        self.descriptors = {}\n",
    "\n",
    "    def _create_path(self, label):\n",
    "        \"\"\"\n",
    "        Creates a standardised path for descriptors with the provided model name\n",
    "        and label to prevent inconsistencies between loading and saving descriptors.\n",
    "        \"\"\"\n",
    "        return f\"{self.base_path}/{self.model.name}/descriptors_{label}.bin\"\n",
    "\n",
    "    def save_descriptors(self, descriptors, label):\n",
    "        \"\"\"\n",
    "        Saves the provided descriptor to the file system at a path derived from\n",
    "        the model name and label.\n",
    "        \"\"\"\n",
    "        path = self.create_path(label)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "        with open(path, \"wb\") as file:\n",
    "            pickle.dump(descriptors, file)\n",
    "\n",
    "    def extract_descriptors(self, dataloader, label):\n",
    "        \"\"\"\n",
    "        Extracts descriptors from the provided model and saves them to this\n",
    "        DescriptorManager.\n",
    "        \"\"\"\n",
    "        descriptors = self.model.descriptors(dataloader, True)\n",
    "        self.descriptors[label] = descriptors\n",
    "\n",
    "        return descriptors\n",
    "\n",
    "    def load_descriptors(self, label):\n",
    "        \"\"\"\n",
    "        Loads and returns the provided descriptors from the file system, based\n",
    "        on the provided model name and label.\n",
    "        \"\"\"\n",
    "        path = self._create_path(label)\n",
    "\n",
    "        with open(path, \"rb\") as file:\n",
    "            self.descriptors[label] = pickle.load(file)\n",
    "\n",
    "            return self.descriptors[label]\n",
    "\n",
    "    def get_descriptors(self, dataloader, label):\n",
    "        \"\"\"\n",
    "        Returns cached descriptors, returns descriptors from the file system or\n",
    "        extracts and saves new descriptors from the model, based on which is\n",
    "        available.\n",
    "\n",
    "        Keyword arguments:\n",
    "        dataloader -- DataLoader with data for which descriptors are retrieved\n",
    "        label -- the label for this data (e.g. \"train\", \"test\", \"fold1\", etc.)\n",
    "        \"\"\"\n",
    "        if label in self.descriptors:\n",
    "            return self.descriptors[label]\n",
    "\n",
    "        try:\n",
    "            return self.load_descriptors(label)\n",
    "        except FileNotFoundError:\n",
    "            descriptors = self.extract_descriptors(dataloader, label)\n",
    "            self.save_descriptors(descriptors, label)\n",
    "\n",
    "            return descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79ee2b-33b2-4974-ac50-950fe278574c",
   "metadata": {},
   "source": [
    "### Perform k-nearest neighbors (kNN) classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655585f1-8758-481c-bc9f-2160c52df57a",
   "metadata": {},
   "source": [
    "First, we define the number of neighbors using which we would like to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1583e334-83bc-4493-914e-1f22a32149d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_list = [2, 3, 5, 8, 13, 18, 21, 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95182658-afa8-4e33-b355-4148bafd7f80",
   "metadata": {},
   "source": [
    "For each `n_neighbors` in the defined list, we perform classification and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082cba94-69c5-4e0c-860f-d1423811b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptorAssessor:\n",
    "    def __init__(self, descriptor_manager):\n",
    "        self.descriptor_manager = descriptor_manager\n",
    "\n",
    "    def _print_accuracies(self, accuracies, label):\n",
    "        for n_neighbors, accuracy in accuracies.items():\n",
    "            print(f\"{self.model.name} accuracy on {label} set for {n_neighbors}-neighbor classification: {accuracy}\")\n",
    "\n",
    "    def _get_descriptors(self, dataset, data_types):\n",
    "        descriptors = {}\n",
    "\n",
    "        for data_type in data_types:\n",
    "            descriptors[data_type] = self.descriptor_manager.get_descriptors(\n",
    "                dataset.dataloaders[data_type],\n",
    "                data_type\n",
    "            )\n",
    "\n",
    "        return descriptors\n",
    "\n",
    "    def assess(self, dataset, n_neighbors_list, train_type, assess_types):\n",
    "        \"\"\"\n",
    "        Assess the performance of kNN-classifiers on model descriptors for\n",
    "        different numbers of neighbors.\n",
    "\n",
    "        Keyword arguments:\n",
    "        dataset -- dictionary of data types (train, test, ...) mapped to Subsets\n",
    "        n_neighbors_list -- list of numbers of neighbors to assess\n",
    "        train_type -- the data type to which the classifier should be fit\n",
    "        assess_types -- the types on which to assess the classifier accuracy\n",
    "        \"\"\"\n",
    "        descriptors = self._get_descriptors(\n",
    "            dataset,\n",
    "            assess_types\n",
    "        )\n",
    "\n",
    "        predictions = dict([(assess_type, {}) for assess_type in assess_types])\n",
    "        accuracies = dict([(assess_type, {}) for assess_type in assess_types])\n",
    "        precisions = dict([(assess_type, {}) for assess_type in assess_types])\n",
    "        recalls = dict([(assess_type, {}) for assess_type in assess_types])\n",
    "        f1_scores = dict([(assess_type, {}) for assess_type in assess_types])\n",
    "\n",
    "        for n_neighbors in n_neighbors_list:\n",
    "            classifier = KNeighborsClassifier(n_neighbors=n_neighbors).fit(\n",
    "                descriptors[train_type],\n",
    "                dataset.targets[train_type]\n",
    "            )\n",
    "\n",
    "            for assess_type in assess_types:\n",
    "                predictions[assess_type][n_neighbors] = classifier.predict(\n",
    "                    descriptors[assess_type]\n",
    "                )\n",
    "                accuracies[assess_type][n_neighbors] = accuracy_score(\n",
    "                    y_true=dataset.targets[assess_type],\n",
    "                    y_pred=predictions[assess_type][n_neighbors]\n",
    "                )\n",
    "                precisions[assess_type][n_neighbors] = precision_score(\n",
    "                    y_true=dataset.targets[assess_type],\n",
    "                    y_pred=predictions[assess_type][n_neighbors],\n",
    "                    average=\"weighted\"\n",
    "                )\n",
    "                recalls[assess_type][n_neighbors] = recall_score(\n",
    "                    y_true=dataset.targets[assess_type],\n",
    "                    y_pred=predictions[assess_type][n_neighbors],\n",
    "                    average=\"weighted\"\n",
    "                )\n",
    "                f1_scores[assess_type][n_neighbors] = f1_score(\n",
    "                    y_true=dataset.targets[assess_type],\n",
    "                    y_pred=predictions[assess_type][n_neighbors],\n",
    "                    average=\"weighted\"\n",
    "                )\n",
    "\n",
    "        return (descriptors, predictions, accuracies, precisions, recalls, f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6db5105-7c1c-4528-ab13-da927464a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualiser:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def _print_accuracies(self, accuracies, label):\n",
    "        for n_neighbors, accuracy in accuracies.items():\n",
    "            print(f\"{self.model.name} accuracy on {label} set for {n_neighbors}-neighbor classification: {accuracy}\")\n",
    "\n",
    "    def _plot_metric(self, ax, metric, label):\n",
    "        return ax.plot(\n",
    "            metric.keys(),\n",
    "            list(metric.values()),\n",
    "            label=label,\n",
    "            marker=\"o\"\n",
    "        )\n",
    "\n",
    "    def visualise_metrics_per_n(self, accuracies, precisions, recalls, f1_scores):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        self._print_accuracies(accuracies[DataType.TEST], DataType.TEST)\n",
    "        print(accuracies[DataType.TEST])\n",
    "        self._plot_metric(ax, accuracies[DataType.TEST], \"accuracy\")\n",
    "        self._plot_metric(ax, precisions[DataType.TEST], \"precision\")\n",
    "        self._plot_metric(ax, recalls[DataType.TEST], \"recall\")\n",
    "        self._plot_metric(ax, f1_scores[DataType.TEST], \"f1_score\")\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"kNN-classification performance using {self.model.name} descriptors\")\n",
    "        ax.set_xlabel(\"k (number of neighbours)\")\n",
    "        ax.set_ylabel(\"score\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de2a8e-5e25-45c9-ae86-77955ce59457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jovyan/2022-1B-DS-CIRI-Project/env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    descriptor_manager = DescriptorManager(model)\n",
    "    descriptor_assessor = DescriptorAssessor(descriptor_manager)\n",
    "\n",
    "    descriptors, predictions, accuracies, precisions, recalls, f1_scores = descriptor_assessor.assess(\n",
    "        dataset,\n",
    "        n_neighbors_list,\n",
    "        DataType.TRAIN,\n",
    "        [DataType.TRAIN, DataType.TEST]\n",
    "    )\n",
    "\n",
    "    visualiser = Visualiser(model)\n",
    "    visualiser.visualise_metrics_per_n(\n",
    "        accuracies,\n",
    "        precisions,\n",
    "        recalls,\n",
    "        f1_scores\n",
    "    )\n",
    "\n",
    "    best_n_test = max(\n",
    "        accuracies[DataType.TEST],\n",
    "        key=accuracies[DataType.TEST].get\n",
    "    )\n",
    "\n",
    "    cm = confusion_matrix(\n",
    "        dataset.targets[DataType.TEST],\n",
    "        predictions[DataType.TEST][best_n_test]\n",
    "    )\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babcf082-8de1-4455-8ea8-c6efe54c7f82",
   "metadata": {},
   "source": [
    "### Visually assess predicted vs. target through PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce636b-2391-4089-894f-fefc16d53430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_against_targets(fit_pca,\n",
    "                                     predictions,\n",
    "                                     targets,\n",
    "                                     n_classes,\n",
    "                                     cmap=None):\n",
    "    \"\"\"Draws a scatter plot of two-dimensional data which highlights\n",
    "    differences between targets and predictions through distinct edge and fill\n",
    "    colors.\"\"\"\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap(\"rainbow\")\n",
    "\n",
    "    if isinstance(targets, list):\n",
    "        targets = np.array(targets)\n",
    "\n",
    "    colors_target = cmap(targets / n_classes)\n",
    "    colors_predictions = cmap(predictions / n_classes)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot targets (ground truth) with fill color representing target class\n",
    "    ax.scatter(fit_pca[:, 0],\n",
    "               fit_pca[:, 1],\n",
    "               facecolors=colors_target,\n",
    "               label=\"target\")\n",
    "\n",
    "    # Plot predictions with edge color representing predicted class\n",
    "    ax.scatter(fit_pca[:, 0],\n",
    "               fit_pca[:, 1],\n",
    "               facecolors=\"none\",\n",
    "               edgecolors=colors_predictions,\n",
    "               label=\"predicted\")\n",
    "\n",
    "    legend = ax.legend()\n",
    "    # Set colors to black to indicate the legend is about marker type, rather\n",
    "    # than color\n",
    "    legend.legendHandles[0].set_color(\"black\")\n",
    "    legend.legendHandles[1].set_edgecolor(\"black\")\n",
    "\n",
    "    return (fig, ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-CIRI-conda",
   "language": "python",
   "name": "ds-ciri-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
